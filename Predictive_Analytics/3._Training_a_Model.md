### 3. Training a Model

To prevent the model for under- or overfitting, a selection was made on the size of the datasets that were used as training-, validation- and test-sets.
After applying different sizes of these datasets, the best measurement to prevent under- and overfitting was estimated at using 2 years as training, 1 year for validation and 1 year for testing.

To tune the parameters for the ARMA and ARIMA models, the numbers of the different components were altered untill the most optimal configuration of hyperparameters were found.
Selecting a 0 in one of these parameters means, that component of the model is not te be used.

To tune the parameters for the selected SARIMA model you can pick an order of numbers and looks like this; ` SARIMA(train_data, (pdq), (PDQs)) `
- p and seasonal P: indicate number of autoregressive terms
- d and seasonal D: indicate differencing that must be done to stationarize series
- q and seasonal Q: indicate number of moving average terms
- s: indicates seasonal length in the data (for instance; 12 is one year.)

[Source](https://machinelearningmastery.com/sarima-for-time-series-forecasting-in-python/)

After trying different configurations of these hyperparameters, one configuration came out as the best one.
- `SARIMA(train_data, (1, 0, 1), (0, 1, 1, 12))`
