### 4. Evaluating a Model
This sub-chapter will compare the different constructed models and explain the differences.

The models I formed were the AR, ARMA, ARIMA and SARIMA model.
From AR to SARIMA the model gets more and more extensive.

The AR model only takes trainingdata.
The ARMA model takes trainingdata, an AutoRegressive factor and a Moving Average factor.
The ARIMA model takes trainingdata, an AutoRegressive factor and an Integrated Moving Average factor where you can select how integrated a certain moving average factor is.
The SARIMA model takes trainingdata, an AutoRegressive factor and an Integrated Moving Average factor and all these factors with seasonal influences.

Because I delt with a dataset that was very extensive relating peaks and seasonal changes, my hypothesis was that the SARIMA model was the best model for making predictions.

Because I started with the AR model with no experience, it was very difficult to code the models in the beginning.
With tips from teachers and help from an experienced coder in my group, I wrote my own code.

The activities of evaluating the first models were unknown to me.
I did not know it was a necessary factor for making conclusions from the models.
I looked at the predictions the models gave and I met with PostNL and other groupmembers if they found the predictions well enough.
This was for the first three models not the case.
When applying the SARIMA model I had figured out to split the data into three sets; train-, validation- and testsets.
These splits made it easier to apply the trainingset to the model to predict the validation- and testsets.
I had also learned to apply a rolling window, which is a form of cross-validation.
After applying the rolling window, the predictions became better for the SARIMA model.
The results can be found in the next sub-chapter.

With every model I have seen that the predictions did not take the peaks into account.
I think this is because the peaks only reveal during the holidays, and because the model has three years of training data, the model only has 5 trainingdata times and this is for the models to little to allow the possibility to adapt to the peaks.

I concluded from these evaluations, that the SARIMA with the rolling window as cross-validation was the best option to use for predicting the number of packages the next day.
